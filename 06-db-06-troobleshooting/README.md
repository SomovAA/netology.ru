# Домашнее задание к занятию "6.6. Troubleshooting"

## Задача 1

Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD операция в MongoDB и её 
нужно прервать. 

Вы как инженер поддержки решили произвести данную операцию:
- напишите список операций, которые вы будете производить для остановки запроса пользователя
- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB

Самый быстрый и болезненный способ без заморачиваний, это перезапуск системы, либо сервиса
```
sudo systemctl stop mongod
sudo systemctl start mongod
```
Также чистка кэша, лишних записей и т.п...
Хоть это и не решает причину проблемы, но в каких-то случаях может отсрочить её повторное появление, а за это время можно будет решить.

Редко прям на prod-е занимаются профилированием запросов, т.к. это уменьшает производительность системы. Обычно смотрят в логи, или иным способом узнают, что был за запрос, и 
работают с ним в тестовой среде. Обычно есть ограниения по времени на выполнение запроса, на соединение и т.п., после чего происходит обрыв с ошибкой, которую в логах можно увидеть.

Можно поиграться с уровнем профилирования, выставить ненадолго в значение 1, с указанием таймаута. Чтобы подобные запросы ловить. Как на prod, так в тестовом режиме с нагрузочным тестированием.
```
db.setProfilingLevel(1, { slowms: 20, sampleRate: 0.42 })
```

После чего отключить
```
db.setProfilingLevel(0)
```
Функционал фильтров для профайлинга огромен, можно установить слежку за запросами конкретного пользователя...
Причем есть разные способы установки, как я понял, при запуске, на лету и разными способами, через файлы, через консоль, через запросы...

Для работы на лету с конкретным запросом в доках написано следующее
```
Terminate Running Operations
Stop in progress MongoDB client operations using db.killOp() and maxTimeMS().

db.killOp(opid)
Terminates an operation as specified by the operation ID. To find operations and their corresponding IDs, see $currentOp or db.currentOp().
```
Т.е. можно ограничить запросы на время выполнения...чтобы не было зависаний бесконечных, используя maxTimeMS

Посмотрим в сторону db.currentOp(), он имеет фильтры, найдем например активные запросы более 3 секунд, либо можно найти незавершившиеся
```
db.currentOp(
   {
     "active" : true,
     "secs_running" : { "$gt" : 3 }
   }
)

db.currentOp(
   {
     "active" : true,
     "numYields" : 0,
     "waitingForLock" : false
   }
)
```
Из результата можно взять параметр opid, и вставить в db.killOp(), таким образом мы прервем этот запрос насильно, используя функционал системы
```
db.killOp(opid)

либо так

db.adminCommand( { "killOp": 1, "op": 724 } )
```

Для более детального анализа конкретного запроса можно использовать explain к самому запросу, либо, используя фильтры, 
найти подходящие, и применить к ним
```
db.runCommand(
   {
     explain: <command>,
     verbosity: <string>,
     comment: <any>
   }
)
```
В некоторых системах есть встроенные подсказчики по оптимизации запросов, в некоторых нету, но можно понять по планировщику, где отрабатывает медленно, и попробовать поиграться с индексами, либо шардированием, либо алгоритмически иначе выстроить таблицы с полями, а мб и поднять больше реплик.

## Задача 2

Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. 
Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса. 

При масштабировании сервиса до N реплик вы увидели, что:
- сначала рост отношения записанных значений к истекшим
- Redis блокирует операции записи

Как вы думаете, в чем может быть проблема?

В редисе есть блокировки на одну операцию, но если блокируются все операции записи, значит происходит что-то глобальное.

Из доков.
```
Latency generated by expires
Basically this means that if the database has many, 
many keys expiring in the same second, 
and these make up at least 25% of the current population of keys 
with an expire set, Redis can block in order to get 
the percentage of keys already expired below 25%.
```

Если в базе данных есть не менее 25% ключей, срок действия которых истекает в одну и ту же секунду, то редис может заблокировать операции.
 
## Задача 3

Перед выполнением задания познакомьтесь с документацией по [Common Mysql errors](https://dev.mysql.com/doc/refman/8.0/en/common-errors.html).

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей, в таблицах базы,
пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

Как вы думаете, почему это начало происходить и как локализовать проблему?

Какие пути решения данной проблемы вы можете предложить?

1) Увеличить время net_read_timeout например с 30 секунд до 60, чтобы данные успели передаться, если ошибка связана с нехваткой времени при передачах больших объемов данных.
2) Увеличить connect_timeout для первоначального соединения, если времени мало из-за того, что сервер находится далеко или соединение медленное.
   Для проверки можно использовать запрос SHOW GLOBAL STATUS LIKE 'Aborted_connects'. За каждый первоначальный крах увеличивается на 1.
3) Максимальный размер объекта BLOB или TEXT определяется его типом, но наибольшее значение, которое вы фактически можете передать между клиентом и сервером, определяется объемом доступной памяти и размером коммуникационных буферов. Вы можете изменить размер буфера сообщений, изменив значение max_allowed_packet переменной, но вы должны сделать это как для сервера, так и для вашей клиентской программы.

## Задача 4

Перед выполнением задания ознакомтесь со статьей [Common PostgreSQL errors](https://www.percona.com/blog/2020/06/05/10-common-postgresql-errors/) из блога Percona.

Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с 
большим объемом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?

Как бы вы решили данную проблему?

oom-killer прекращает процесс из-за недостатка ОП.

1) Можно попробовать swap подключить, или увеличить его размеры, если он уже подключен.
2) Увеличить размер ОП.
3) Мб оптимизировать то, что потребляет столько памяти.
4) Мб на машине, где установлен PG, есть что-то лишнее, что тоже потребляет память...лучше PG на отдельной машине поднять, без лишнего софта.

### Дополнение
Можно поиграть с параметрами, которые регулируют память в Postgres из основных это: max_connections, shared_buffer, work_mem, effective_cache_size, maintenance_work_mem.

shared_buffer - этот параметр устанавливает, сколько выделенной памяти будет использоваться PostgreSQL для кеширования.

wal_buffers - PostgreSQL сначала записывает записи в WAL (журнал пред записи) в буферы, а затем эти буферы сбрасываются на диск. Размер буфера по умолчанию, определенный wal_buffers, составляет 16 МБ. Но если у нас много одновременных подключений, то более высокое значение может повысить производительность.

effective_cache_size - предоставляет оценку памяти, доступной для кэширования диска. Это всего лишь ориентир, а не точный объем выделенной памяти или кеша. Он не выделяет фактическую память, но сообщает оптимизатору объем кеша, доступный в ядре. Если значение этого параметра установлено слишком низким, планировщик запросов может принять решение не использовать некоторые индексы, даже если они будут полезны. Поэтому установка большого значения всегда имеет смысл.

work_mem - если нам нужно выполнить сложную сортировку, увеличьте значение work_mem для получения хороших результатов. Сортировка в памяти происходит намного быстрее, чем сортировка данных на диске. Установка очень высокого значения может стать причиной узкого места в памяти для нашей среды, поскольку этот параметр относится к операции сортировки пользователя.

maintenance_work_mem - это параметр памяти, используемый для задач обслуживания.